{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/satyajitghana/PadhAI-Course/blob/master/14_PyTorchIntro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0kPS-MnWT7f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/home/piyushmishra/miniconda3/envs/newenv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJyLCI8PcPZq"
   },
   "source": [
    "## Initialise tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "NV2jveDIayX-",
    "outputId": "d284f6ca-9e6e-4306-fd09-d8d150792e9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[0.1648, 0.3552],\n",
      "        [0.9503, 0.4890],\n",
      "        [0.2483, 0.4572]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3, 2)\n",
    "print(x)\n",
    "x = torch.zeros(3, 2)\n",
    "print(x)\n",
    "x = torch.rand(3, 2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "BuAQVNaPFN1P",
    "outputId": "a9bcfacb-b586-4618-d945-816d99ea8725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5993e-37, 4.5856e-41],\n",
      "        [4.5852e-37, 4.5856e-41],\n",
      "        [4.5467e-37, 4.5856e-41]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(3, 2)\n",
    "print(x)\n",
    "y = torch.zeros_like(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bWrOMr-hFbwo",
    "outputId": "554dce83-7312-4419-ea6e-0a172ef94403"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.linspace(0, 1, steps=5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "l_QspfvYEtuB",
    "outputId": "f5ff8117-30d0-4bfa-a4f4-033503313d46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2], \n",
    "                 [3, 4], \n",
    "                 [5, 6]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wKub-KJLcSDJ"
   },
   "source": [
    "## Slicing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "UxSlfSVrbH8h",
    "outputId": "11514c9d-26ff-4bbb-bafc-6479842a8dd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "tensor([2, 4, 6])\n",
      "tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())\n",
    "print(x[:, 1]) \n",
    "print(x[0, :]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "AGWkj2utcrz9",
    "outputId": "7cf306ee-6546-4df7-c166-65cea6183097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "y = x[1, 1]\n",
    "print(y)\n",
    "print(y.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6YvWGrX0cUpf"
   },
   "source": [
    "## Reshaping tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "mn1q-Hm7b6hP",
    "outputId": "2b435147-ce49-4998-c147-181dc0e84158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "y = x.view(2, 3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "1EbIwPvBF4Lg",
    "outputId": "85ad9d7d-cb78-4bfe-f431-78ee57ef44b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6]])\n"
     ]
    }
   ],
   "source": [
    "y = x.view(6,-1) \n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2XxOq0ObdXEC"
   },
   "source": [
    "## Simple Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "Rv4jjqBVdIB2",
    "outputId": "dfd41138-ea3e-4751-cdfe-3af61ff063c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 2.]])\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones([3, 2])\n",
    "y = torch.ones([3, 2])\n",
    "z = x + y\n",
    "print(z)\n",
    "z = x - y\n",
    "print(z)\n",
    "z = x * y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "dVHnXB78dl8s",
    "outputId": "da41ac3c-1857-4e54-eb88-7a8509ada653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 2.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "z = y.add(x)\n",
    "print(z)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "LewBBuz_eL1m",
    "outputId": "6ccfac1e-9e72-46dc-94f7-cd193722f9bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 2.]])\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# modify in-place\n",
    "z = y.add_(x)\n",
    "print(z)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PDuBSdzTc2Bq"
   },
   "source": [
    "## Numpy <> PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "NlvqO8_1ccML",
    "outputId": "6a2eef73-76a3-4860-bd35-d839f26f80e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'numpy.ndarray'>\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "x_np = x.numpy()\n",
    "print(type(x), type(x_np))\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "tLhS3Hrmc-M2",
    "outputId": "d693da4c-7ba3-47bd-97b3-28a0047127b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.13793665  0.62926498 -1.70186599 -1.66115142  1.05646883]\n",
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n",
      "tensor([ 1.1379,  0.6293, -1.7019, -1.6612,  1.0565], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.random.randn(5)\n",
    "print(a)\n",
    "# copies the reference as well\n",
    "a_pt = torch.from_numpy(a)\n",
    "print(type(a), type(a_pt))\n",
    "print(a_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "kwZhRYVtdp-X",
    "outputId": "fe79d21d-b2c7-4e79-e539-b6b6606e4cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.13793665  1.62926498 -0.70186599 -0.66115142  2.05646883]\n",
      "tensor([ 2.1379,  1.6293, -0.7019, -0.6612,  2.0565], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(a_pt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "6z-Mhf2hewcU",
    "outputId": "a9fd2bb2-8af6-4f15-94b3-f6ecc6f30933"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 144 ms, sys: 104 ms, total: 248 ms\n",
      "Wall time: 139 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(100):\n",
    "  a = np.random.randn(100,100)\n",
    "  b = np.random.randn(100,100)\n",
    "  c = np.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "aFzIX2qge3x9",
    "outputId": "b2a0b8dd-5923-4fdb-b144-135d375d7402"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.3 ms, sys: 1.33 ms, total: 28.6 ms\n",
      "Wall time: 80.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(100):\n",
    "  a = torch.randn([100, 100])\n",
    "  b = torch.randn([100, 100])\n",
    "  c = torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Pdat0Hnm6hGA",
    "outputId": "8dc382f2-3e56-4ef3-d99e-400dfe05e6d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 743 ms, total: 1min 25s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "  a = np.random.randn(10000,10000)\n",
    "  b = np.random.randn(10000,10000)\n",
    "  c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "XlRx5OKl6kEq",
    "outputId": "5d40c555-6796-43b8-aff9-71169f193207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.8 s, sys: 22 ms, total: 17.8 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "  a = torch.randn([10000, 10000])\n",
    "  b = torch.randn([10000, 10000])\n",
    "  c = a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "de5YwtfUgMWO"
   },
   "source": [
    "## CUDA support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-nI4nYcWgY1B",
    "outputId": "d1897387-db5e-4b6c-997c-ecfa933c2879"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "_3E-PMC1gfKU",
    "outputId": "c9d126a9-2bc5-4a09-83f0-575676f80eab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.cuda.device object at 0x7f0ec649ac50>\n",
      "Tesla K80\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_eZYxVpMgor4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/home/piyushmishra/miniconda3/envs/newenv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "cuda0 = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "j1r7y57x9JZU",
    "outputId": "9490dee3-f2e5-4f85-d4b5-d7384a983634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 2.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(3, 2, device=cuda0)\n",
    "b = torch.ones(3, 2, device=cuda0)\n",
    "c = a + b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "wSt3W1s-_Gc3",
    "outputId": "74495e3f-efe6-4f6f-fbf2-3e6bc1fda33e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "sVfOAU2EfTXB",
    "outputId": "2308119e-1809-4393-d128-34d0247b80ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 198 ms, total: 1min 25s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "  a = np.random.randn(10000,10000)\n",
    "  b = np.random.randn(10000,10000)\n",
    "  np.add(b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "G9GLUek5hCfn",
    "outputId": "e58ed319-7404-4f5d-f770-5c724c848097"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.7 s, sys: 169 ms, total: 17.8 s\n",
      "Wall time: 17.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "  a_cpu = torch.randn([10000, 10000])\n",
    "  b_cpu = torch.randn([10000, 10000])\n",
    "  b_cpu.add_(a_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "FqSYioGrgyMI",
    "outputId": "0cc06308-c112-4967-ddac-7103cc547cbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.58 ms, sys: 4 ms, total: 6.57 ms\n",
      "Wall time: 9.65 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "  a = torch.randn([10000, 10000], device=cuda0)\n",
    "  b = torch.randn([10000, 10000], device=cuda0)\n",
    "  b.add_(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "colab_type": "code",
    "id": "Kjsl8xRFjPtT",
    "outputId": "3cb042b1-6745-437e-bcca-9eae5fd0159c"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d07f7d3ebc58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'for i in range(10):\\n  a = np.random.randn(10000,10000)\\n  b = np.random.randn(10000,10000)\\n  np.matmul(b, a)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "  a = np.random.randn(10000,10000)\n",
    "  b = np.random.randn(10000,10000)\n",
    "  np.matmul(b, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "avFqbCgXjT3F"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "  a_cpu = torch.randn([10000, 10000])\n",
    "  b_cpu = torch.randn([10000, 10000])\n",
    "  torch.matmul(a_cpu, b_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "hFfMhN2gjlZJ",
    "outputId": "b3d11d01-7ee1-49a6-9869-310a0172de51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.96 ms, sys: 3.99 ms, total: 12.9 ms\n",
      "Wall time: 17.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10):\n",
    "  a = torch.randn([10000, 10000], device=cuda0)\n",
    "  b = torch.randn([10000, 10000], device=cuda0)\n",
    "  torch.matmul(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P_6TU64Gi7jv"
   },
   "source": [
    "## Autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "PjySsLMThEX7",
    "outputId": "c46962bf-4790-476c-ae1e-e5e844da0cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.ones([3, 2], requires_grad=True)    \n",
    "# with requires_grad we can say \n",
    "# that we can differentiate any function which is\n",
    "#  related to x(z) diff wrt to x\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "neb3oFWBjAtJ",
    "outputId": "b9ae944e-0641-44cc-9275-3644e20e6a82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 6.],\n",
      "        [6., 6.],\n",
      "        [6., 6.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x*x + 5\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [2., 2.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s= y.sum()\n",
    "s.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "5M0pnstAjLa-",
    "outputId": "efb8a8ff-d184-48a6-a35a-09707d62d790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[37., 37.],\n",
      "        [37., 37.],\n",
      "        [37., 37.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y*y + 1\n",
    "print(z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wHHDSmiUkMOw",
    "outputId": "835b0b1b-446c-4abe-f10c-0da17b70b634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(222., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "t = torch.sum(z)\n",
    "print(t)\n",
    "# till now it is a forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AXj896azkM_S"
   },
   "outputs": [],
   "source": [
    "t.backward()   # from now \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "wSYAcNN1lAWS",
    "outputId": "3c49034a-32c2-42f3-e875-b06aa925fed2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12., 12.],\n",
      "        [12., 12.],\n",
      "        [12., 12.]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)  # derivative of t wrt to x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6nrD44oJiEIY"
   },
   "source": [
    "$t = \\sum_i z_i, z_i = y_i^2 + 1, y_i = x_i + 5$\n",
    "\n",
    "$\\frac{\\partial t}{\\partial x_i} = \\frac{\\partial z_i}{\\partial x_i} = \\frac{\\partial z_i}{\\partial y_i} \\frac{\\partial y_i}{\\partial x_i} = 2y_i \\times 1$\n",
    "\n",
    "\n",
    "At x = 1, y = 6, $\\frac{\\partial t}{\\partial x_i} = 12$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t wrt to xi can be written as zi wrt xi because for any other zj where j not equal to i \n",
    "zj wrt to xi will be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "ZFCWPPAP6ipv",
    "outputId": "25fae8db-4bbb-474d-9126-18bc0deb5f27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9975, 0.9975],\n",
      "        [0.9975, 0.9975],\n",
      "        [0.9975, 0.9975]], grad_fn=<MulBackward0>)\n",
      "tensor([[0.0025, 0.0025],\n",
      "        [0.0025, 0.0025],\n",
      "        [0.0025, 0.0025]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones([3, 2], requires_grad=True)\n",
    "y = x + 5\n",
    "r = 1/(1 + torch.exp(-y))\n",
    "print(r)\n",
    "# we sum up even though we want to diff r wrt x\n",
    "# if you want to call r.backward() then if we have tensors with multiple values i must\n",
    "# have an argument.\n",
    "s = torch.sum(r)\n",
    "s.backward()\n",
    "print(x.grad)   # ri(1-ri) where ri is 0.9975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you call backward directly on r then pass an argument same size(all ones) as an r \n",
    "# r.backward() gives you differentiate of r to x, a will act as a diff s wrt r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "Ts1wsONqlE5h",
    "outputId": "1ab04606-f047-44a6-b2d7-9e27d4c3aa8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0025, 0.0025],\n",
      "        [0.0025, 0.0025],\n",
      "        [0.0025, 0.0025]])\n"
     ]
    }
   ],
   "source": [
    "# A bit tricky concept\n",
    "x = torch.ones([3, 2], requires_grad=True)\n",
    "y = x + 5\n",
    "r = 1/(1 + torch.exp(-y))\n",
    "a = torch.ones([3, 2])\n",
    "r.backward(a)  # is computing derivative of r wrt x\n",
    "print(x.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial{s}}{\\partial{x}} = \\frac{\\partial{s}}{\\partial{r}} \\cdot \\frac{\\partial{r}}{\\partial{x}}$\n",
    "\n",
    "For the above code $a$ represents $\\frac{\\partial{s}}{\\partial{r}}$ and then $x.grad$ gives directly $\\frac{\\partial{s}}{\\partial{x}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AKhxwdYUpUfj"
   },
   "source": [
    "## Autodiff example that looks like what we have been doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "THNkQLR6mmpO"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(20, requires_grad=True)  # I have 20 data pts\n",
    "y = 3*x - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-t4_8qgdnjDk"
   },
   "outputs": [],
   "source": [
    "w = torch.randn(1, requires_grad=True)\n",
    "b = torch.randn(1, requires_grad=True)\n",
    "\n",
    "y_hat = w*x + b\n",
    "\n",
    "loss = torch.sum((y_hat - y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Gvpc37u-o6ob",
    "outputId": "a66ab0b5-f562-425c-c000-b20f2accdbc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(166.9963, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-tnKq6DXo-RB"
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "I38qmZLhpM2F",
    "outputId": "1050f8b0-41af-4633-b3ad-fe3c516c28c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-120.3507]) tensor([-51.7662])\n"
     ]
    }
   ],
   "source": [
    "print(w.grad, b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WfDV6saTq8XA"
   },
   "source": [
    "## Do it in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "ivmJgJQTpN79",
    "outputId": "cb06e805-2f97-4f87-eca9-fbe3b938880c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n",
      "tensor(215.7822, grad_fn=<SumBackward0>)\n",
      "1.4472225904464722 -0.14039993286132812\n",
      "tensor(54.3767, grad_fn=<SumBackward0>)\n",
      "1.7493094205856323 -0.4729774296283722\n",
      "tensor(78.2562, grad_fn=<SumBackward0>)\n",
      "2.204193353652954 -1.1253607273101807\n",
      "tensor(30.1123, grad_fn=<SumBackward0>)\n",
      "2.559617280960083 -1.4905364513397217\n",
      "tensor(9.3386, grad_fn=<SumBackward0>)\n",
      "2.745514392852783 -1.69645094871521\n",
      "tensor(2.2904, grad_fn=<SumBackward0>)\n",
      "2.8225016593933105 -1.7828181982040405\n",
      "tensor(1.1706, grad_fn=<SumBackward0>)\n",
      "2.857426881790161 -1.8620781898498535\n",
      "tensor(0.5683, grad_fn=<SumBackward0>)\n",
      "2.891460418701172 -1.9093002080917358\n",
      "tensor(0.4083, grad_fn=<SumBackward0>)\n",
      "2.9301931858062744 -1.9529813528060913\n",
      "tensor(0.1390, grad_fn=<SumBackward0>)\n",
      "2.9558463096618652 -1.9740253686904907\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "learning_rate = 0.01\n",
    "\n",
    "w = torch.tensor([1.], requires_grad=True)\n",
    "b = torch.tensor([1.], requires_grad=True)\n",
    "\n",
    "print(w.item(), b.item())\n",
    "\n",
    "for i in range(10):\n",
    "  x = torch.randn([20, 1])\n",
    "\n",
    "  y = 3*x - 2\n",
    "  \n",
    "  y_hat = w*x + b\n",
    "  loss = torch.sum((y_hat - y)**2)\n",
    "  print(loss)\n",
    "  loss.backward()\n",
    "   # we have already build our forward pass if we don't write this \n",
    "   # w = w - lr*w.grad() would also go into the forward pass(computation graph)\n",
    "   #  which we don't want.\n",
    "\n",
    "  with torch.no_grad():                \n",
    "    w -= learning_rate * w.grad\n",
    "    b -= learning_rate * b.grad\n",
    "    \n",
    "\n",
    "    # we want gradient to set to zero so that in next epoch again compute\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "  print(w.item(), b.item())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=torch.randn([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8418, -0.7089, -0.0119],\n",
       "        [ 0.0494,  0.5947, -0.2307]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vyOqrZZiuLkl"
   },
   "source": [
    "## Do it for a large problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "qq3Iykk1rMfh",
    "outputId": "42f25245-7d44-4bf5-aa1c-ad5c6775efeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5015039443969727 -9.189061164855957\n",
      "0.5005476474761963 -26.992393493652344\n",
      "0.4863433539867401 26.584476470947266\n",
      "0.41137972474098206 -422.5045471191406\n",
      "-0.5429626703262329 944.7420654296875\n",
      "-1.9854642152786255 10659.181640625\n",
      "-17.474288940429688 47843.390625\n",
      "-24.298166275024414 5773.3515625\n",
      "-170.1705780029297 370007.75\n",
      "343.8456726074219 1344474.25\n",
      "3244.939208984375 -7179179.0\n",
      "3533.00927734375 -3618520.5\n",
      "11159.9375 -110736432.0\n",
      "338988.6875 1084698752.0\n",
      "1765607.0 13416030208.0\n",
      "-12109914.0 -8864036864.0\n",
      "-41019400.0 -82148876288.0\n",
      "-47863388.0 -13211230208.0\n",
      "-279533408.0 -381161340928.0\n",
      "-529739552.0 -951628333056.0\n",
      "-833850944.0 5373071196160.0\n",
      "3044702720.0 -69276899737600.0\n",
      "36210483200.0 211562136600576.0\n",
      "16402895872.0 -864695028285440.0\n",
      "-4020632027136.0 -7740021767405568.0\n",
      "-13712084697088.0 -7.317858909211853e+16\n",
      "-73129065971712.0 5.517166382573158e+16\n",
      "40121592184832.0 1.1846775994402734e+18\n",
      "83425327316992.0 -7.899324466646221e+17\n",
      "-170611888357376.0 1.1371482406482608e+19\n",
      "6.147486334006067e+16 1.8053863060435422e+20\n",
      "2.52310843100758e+17 -3.2484625960334996e+20\n",
      "-1.184680073341436e+18 -2.8267546748632695e+21\n",
      "-4.832580653226656e+18 1.2409150859262254e+22\n",
      "5.88810247004278e+19 -1.4504287555589867e+23\n",
      "-2.6186153645066682e+20 -1.8250649419598496e+24\n",
      "5.474404570245735e+21 2.4605136548328274e+25\n",
      "-1.2661276777921262e+23 2.9011860332184073e+26\n",
      "-7.836287671062651e+22 3.3522843730038673e+25\n",
      "-2.9466629023520183e+22 -2.1497245247690753e+26\n",
      "3.358681469661449e+22 -4.8591911487526896e+26\n",
      "5.227359072254371e+23 -1.7692310610322504e+27\n",
      "1.3220710861185478e+24 1.095599531291182e+28\n",
      "1.5739308528482173e+25 -1.5084896096921134e+29\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:12\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learning_rate = 0.001\n",
    "N = 10000000\n",
    "epochs = 200\n",
    "\n",
    "w = torch.rand([N], requires_grad=True)\n",
    "b = torch.ones([1], requires_grad=True)\n",
    "\n",
    "# print(torch.mean(w).item(), b.item())\n",
    "\n",
    "for i in range(epochs):\n",
    "  \n",
    "  x = torch.randn([N])\n",
    "  y = torch.dot(3*torch.ones([N]), x) - 2\n",
    "  \n",
    "  y_hat = torch.dot(w, x) + b\n",
    "  loss = torch.sum((y_hat - y)**2)\n",
    "  \n",
    "  loss.backward()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    #before loss.backward() it is forward prop and after that it is backward prop so till\n",
    "    # now we have done both forward and back prop but now if we want to update the paramerters of\n",
    "    # the model with the below pytorch thinks that  w=w-somehting might again be a continous of a \n",
    "    # forward pass(continue to build the computational graph) or to say i don't want any backprop\n",
    "\n",
    "    w -= learning_rate * w.grad\n",
    "    b -= learning_rate * b.grad\n",
    "    \n",
    "    w.grad.zero_()     # set gradients to zero\n",
    "    b.grad.zero_()\n",
    "\n",
    "  # print(torch.mean(w).item(), b.item())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "owaeEn4A01zF",
    "outputId": "55c3b0e2-6efe-4ce4-92cd-c9bed6c85caf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 798 ms, sys: 506 ms, total: 1.3 s\n",
      "Wall time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learning_rate = 0.001\n",
    "N = 10000000\n",
    "epochs = 200\n",
    "\n",
    "# Every tensor has to be on the device\n",
    "\n",
    "w = torch.rand([N], requires_grad=True, device=cuda0)\n",
    "b = torch.ones([1], requires_grad=True, device=cuda0)\n",
    "\n",
    "# print(torch.mean(w).item(), b.item())\n",
    "\n",
    "for i in range(epochs):\n",
    "  \n",
    "  x = torch.randn([N], device=cuda0)\n",
    "  y = torch.dot(3*torch.ones([N], device=cuda0), x) - 2\n",
    "  \n",
    "  y_hat = torch.dot(w, x) + b\n",
    "  loss = torch.sum((y_hat - y)**2)\n",
    "  \n",
    "  loss.backward()\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    w -= learning_rate * w.grad\n",
    "    b -= learning_rate * b.grad\n",
    "    \n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "\n",
    "  #print(torch.mean(w).item(), b.item())\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My own code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/home/piyushmishra/miniconda3/envs/newenv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.randn([20])\n",
    "y=5*x-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=torch.ones([1],requires_grad=True)\n",
    "b=torch.ones([1],requires_grad=True)\n",
    "lr=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5685.1050, grad_fn=<PowBackward0>)\n",
      "tensor(5594.2095, grad_fn=<PowBackward0>)\n",
      "tensor(5504.7656, grad_fn=<PowBackward0>)\n",
      "tensor(5416.7529, grad_fn=<PowBackward0>)\n",
      "tensor(5330.1475, grad_fn=<PowBackward0>)\n",
      "tensor(5244.9258, grad_fn=<PowBackward0>)\n",
      "tensor(5161.0684, grad_fn=<PowBackward0>)\n",
      "tensor(5078.5513, grad_fn=<PowBackward0>)\n",
      "tensor(4997.3525, grad_fn=<PowBackward0>)\n",
      "tensor(4917.4517, grad_fn=<PowBackward0>)\n",
      "tensor(4838.8291, grad_fn=<PowBackward0>)\n",
      "tensor(4761.4634, grad_fn=<PowBackward0>)\n",
      "tensor(4685.3354, grad_fn=<PowBackward0>)\n",
      "tensor(4610.4238, grad_fn=<PowBackward0>)\n",
      "tensor(4536.7100, grad_fn=<PowBackward0>)\n",
      "tensor(4464.1753, grad_fn=<PowBackward0>)\n",
      "tensor(4392.7998, grad_fn=<PowBackward0>)\n",
      "tensor(4322.5649, grad_fn=<PowBackward0>)\n",
      "tensor(4253.4536, grad_fn=<PowBackward0>)\n",
      "tensor(4185.4468, grad_fn=<PowBackward0>)\n",
      "tensor(4118.5288, grad_fn=<PowBackward0>)\n",
      "tensor(4052.6792, grad_fn=<PowBackward0>)\n",
      "tensor(3987.8833, grad_fn=<PowBackward0>)\n",
      "tensor(3924.1233, grad_fn=<PowBackward0>)\n",
      "tensor(3861.3823, grad_fn=<PowBackward0>)\n",
      "tensor(3799.6448, grad_fn=<PowBackward0>)\n",
      "tensor(3738.8945, grad_fn=<PowBackward0>)\n",
      "tensor(3679.1155, grad_fn=<PowBackward0>)\n",
      "tensor(3620.2920, grad_fn=<PowBackward0>)\n",
      "tensor(3562.4082, grad_fn=<PowBackward0>)\n",
      "tensor(3505.4509, grad_fn=<PowBackward0>)\n",
      "tensor(3449.4043, grad_fn=<PowBackward0>)\n",
      "tensor(3394.2537, grad_fn=<PowBackward0>)\n",
      "tensor(3339.9841, grad_fn=<PowBackward0>)\n",
      "tensor(3286.5830, grad_fn=<PowBackward0>)\n",
      "tensor(3234.0359, grad_fn=<PowBackward0>)\n",
      "tensor(3182.3281, grad_fn=<PowBackward0>)\n",
      "tensor(3131.4480, grad_fn=<PowBackward0>)\n",
      "tensor(3081.3806, grad_fn=<PowBackward0>)\n",
      "tensor(3032.1138, grad_fn=<PowBackward0>)\n",
      "tensor(2983.6353, grad_fn=<PowBackward0>)\n",
      "tensor(2935.9316, grad_fn=<PowBackward0>)\n",
      "tensor(2888.9902, grad_fn=<PowBackward0>)\n",
      "tensor(2842.8003, grad_fn=<PowBackward0>)\n",
      "tensor(2797.3477, grad_fn=<PowBackward0>)\n",
      "tensor(2752.6223, grad_fn=<PowBackward0>)\n",
      "tensor(2708.6121, grad_fn=<PowBackward0>)\n",
      "tensor(2665.3052, grad_fn=<PowBackward0>)\n",
      "tensor(2622.6914, grad_fn=<PowBackward0>)\n",
      "tensor(2580.7581, grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_lt=[]\n",
    "for i in range(50):\n",
    "    y_hat= w*x+b\n",
    "    loss = torch.sum(y_hat-y)**2\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    loss_lt.append(loss.item())\n",
    "    with torch.no_grad():    \n",
    "        w -= lr * w.grad\n",
    "        b -= lr * b.grad\n",
    "    \n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcfc1d16310>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x=torch.randn([20,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w= torch.ones([1,1],requires_grad=True)\n",
    "b=torch.ones([1,1],requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]], requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=5*x-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.5071]], requires_grad=True) tensor([[-3.9235]], requires_grad=True)\n",
      "tensor([[4.7008]], requires_grad=True) tensor([[-6.5495]], requires_grad=True)\n",
      "tensor([[5.2323]], requires_grad=True) tensor([[-7.9688]], requires_grad=True)\n",
      "tensor([[5.4361]], requires_grad=True) tensor([[-8.7509]], requires_grad=True)\n",
      "tensor([[5.4832]], requires_grad=True) tensor([[-9.1935]], requires_grad=True)\n",
      "tensor([[5.4598]], requires_grad=True) tensor([[-9.4528]], requires_grad=True)\n",
      "tensor([[5.4087]], requires_grad=True) tensor([[-9.6115]], requires_grad=True)\n",
      "tensor([[5.3505]], requires_grad=True) tensor([[-9.7134]], requires_grad=True)\n",
      "tensor([[5.2944]], requires_grad=True) tensor([[-9.7822]], requires_grad=True)\n",
      "tensor([[5.2444]], requires_grad=True) tensor([[-9.8308]], requires_grad=True)\n",
      "tensor([[5.2013]], requires_grad=True) tensor([[-9.8665]], requires_grad=True)\n",
      "tensor([[5.1651]], requires_grad=True) tensor([[-9.8935]], requires_grad=True)\n",
      "tensor([[5.1349]], requires_grad=True) tensor([[-9.9145]], requires_grad=True)\n",
      "tensor([[5.1101]], requires_grad=True) tensor([[-9.9311]], requires_grad=True)\n",
      "tensor([[5.0898]], requires_grad=True) tensor([[-9.9442]], requires_grad=True)\n",
      "tensor([[5.0731]], requires_grad=True) tensor([[-9.9548]], requires_grad=True)\n",
      "tensor([[5.0595]], requires_grad=True) tensor([[-9.9633]], requires_grad=True)\n",
      "tensor([[5.0484]], requires_grad=True) tensor([[-9.9702]], requires_grad=True)\n",
      "tensor([[5.0394]], requires_grad=True) tensor([[-9.9758]], requires_grad=True)\n",
      "tensor([[5.0321]], requires_grad=True) tensor([[-9.9803]], requires_grad=True)\n",
      "tensor([[5.0261]], requires_grad=True) tensor([[-9.9840]], requires_grad=True)\n",
      "tensor([[5.0212]], requires_grad=True) tensor([[-9.9870]], requires_grad=True)\n",
      "tensor([[5.0173]], requires_grad=True) tensor([[-9.9894]], requires_grad=True)\n",
      "tensor([[5.0140]], requires_grad=True) tensor([[-9.9914]], requires_grad=True)\n",
      "tensor([[5.0114]], requires_grad=True) tensor([[-9.9930]], requires_grad=True)\n",
      "tensor([[5.0093]], requires_grad=True) tensor([[-9.9943]], requires_grad=True)\n",
      "tensor([[5.0076]], requires_grad=True) tensor([[-9.9954]], requires_grad=True)\n",
      "tensor([[5.0061]], requires_grad=True) tensor([[-9.9962]], requires_grad=True)\n",
      "tensor([[5.0050]], requires_grad=True) tensor([[-9.9969]], requires_grad=True)\n",
      "tensor([[5.0041]], requires_grad=True) tensor([[-9.9975]], requires_grad=True)\n",
      "tensor([[5.0033]], requires_grad=True) tensor([[-9.9980]], requires_grad=True)\n",
      "tensor([[5.0027]], requires_grad=True) tensor([[-9.9984]], requires_grad=True)\n",
      "tensor([[5.0022]], requires_grad=True) tensor([[-9.9987]], requires_grad=True)\n",
      "tensor([[5.0018]], requires_grad=True) tensor([[-9.9989]], requires_grad=True)\n",
      "tensor([[5.0014]], requires_grad=True) tensor([[-9.9991]], requires_grad=True)\n",
      "tensor([[5.0012]], requires_grad=True) tensor([[-9.9993]], requires_grad=True)\n",
      "tensor([[5.0010]], requires_grad=True) tensor([[-9.9994]], requires_grad=True)\n",
      "tensor([[5.0008]], requires_grad=True) tensor([[-9.9995]], requires_grad=True)\n",
      "tensor([[5.0006]], requires_grad=True) tensor([[-9.9996]], requires_grad=True)\n",
      "tensor([[5.0005]], requires_grad=True) tensor([[-9.9997]], requires_grad=True)\n",
      "tensor([[5.0004]], requires_grad=True) tensor([[-9.9997]], requires_grad=True)\n",
      "tensor([[5.0003]], requires_grad=True) tensor([[-9.9998]], requires_grad=True)\n",
      "tensor([[5.0003]], requires_grad=True) tensor([[-9.9998]], requires_grad=True)\n",
      "tensor([[5.0002]], requires_grad=True) tensor([[-9.9999]], requires_grad=True)\n",
      "tensor([[5.0002]], requires_grad=True) tensor([[-9.9999]], requires_grad=True)\n",
      "tensor([[5.0001]], requires_grad=True) tensor([[-9.9999]], requires_grad=True)\n",
      "tensor([[5.0001]], requires_grad=True) tensor([[-9.9999]], requires_grad=True)\n",
      "tensor([[5.0001]], requires_grad=True) tensor([[-9.9999]], requires_grad=True)\n",
      "tensor([[5.0001]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0001]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0001]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n",
      "tensor([[5.0000]], requires_grad=True) tensor([[-10.0000]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "lr=0.01\n",
    "for i in range(800):\n",
    "    y_pred= w*x+b\n",
    "    loss=torch.sum((y-y_pred)**2)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w-= lr* w.grad\n",
    "        b-= lr* b.grad\n",
    "\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    print(w,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "14_PyTorchIntro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "52e30b6a095111cac9bf6069db8bddb593b9ee13c71f5b5c46d2273b3df6f796"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
